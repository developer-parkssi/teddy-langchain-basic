{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 10 Ollama 설치 후 Modelfile 설정하기\n",
    "\n",
    "- 허깅페이스(HuggingFace) 오픈 모델 페이지를 열고 **Files and versions** 탭에서 오픈모델을 다운로드 (.gguf 확장자)\n",
    "- 모델 설치한 경로에 ModelFile 생성. 해당 모델에서 공개한 양식을 복사해서 붙여넣기\n",
    "\n",
    "```\n",
    "FROM EEVE-Korean-Instruct-10.8B-v1.0-Q4_0.gguf\n",
    "\n",
    "TEMPLATE \"\"\"{{- if .System }}\n",
    "<s>{{ .System }}</s>\n",
    "{{- end }}\n",
    "<s>Human:\n",
    "{{ .Prompt }}</s>\n",
    "<s>Assistant:\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM \"\"\"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\"\"\"\n",
    "\n",
    "PARAMETER stop <s>\n",
    "PARAMETER stop </s>\n",
    "```\n",
    "\n",
    "- 템플릿 안에 \\<s\\>, \\</s\\>로 묶은 부분은 **스페셜 토큰**, 출력되는 프롬프트의 시작과 끝을 지정"
   ],
   "id": "1ba21788ac0cf09f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 11 Ollama 모델 생성하고 ChatOllama 활용하기\n",
    "\n",
    "- Ollama에 업로드된 기성 모델을 다운로드해서 모델을 만들고 실행\n",
    "\n",
    "**Ollama 모델 생성하기**\n",
    "\n",
    "- `ollama list`로 현재 설치된 모델 확인\n",
    "- `ollama pull <name-of-model>` 명령어로 Ollama에서 제공하는 모델 다운로드\n",
    "- `ollama create <model-name> -f <path-to-modelfile>` 명령어로 Modelfile로부터 커스텀 모델 생성"
   ],
   "id": "63d7a60186640d6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Ollama 모델과 LangChain 활용하기**",
   "id": "3b4006c9a96fdf0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "logging.langsmith(\"CH04-Models\")"
   ],
   "id": "ecb0a09d4b06f1aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "# Ollama 모델을 불러옵니다.\n",
    "llm = ChatOllama(model=\"EEVE-Korean-Instruct-10.8B-v1.0-Q4_0.gguf:latest\")\n",
    "\n",
    "# 프롬프트\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic} 에 대하여 간략히 설명해 줘.\")\n",
    "\n",
    "# 체인 생성\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 간결성을 위해 응답은 터미널에 출력됩니다.\n",
    "answer = chain.stream({\"topic\": \"deep learning\"})\n",
    "\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ],
   "id": "a9490eb125943152"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**JSON 형식으로 출력하기**\n",
    "\n",
    "- `format` 플래그는 모델이 JSON 형식으로 응답을 생성하도록 강제"
   ],
   "id": "e273a4c687c20d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma:7b\",  # 사용할 언어 모델을 지정합니다.\n",
    "    format=\"json\",  # 입출력 형식을 JSON으로 설정합니다.\n",
    "    temperature=0,\n",
    ")"
   ],
   "id": "d8c9b7bed59ad260"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- JSON 형식의 답변을 받기 위해서는 `\"response in JSON format.\"` 이 프롬프트에 포함되어야 한다",
   "id": "4e7234369389b6c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JSON 형식의 답변을 요구하는 프롬프트 작성\n",
    "prompt = \"유럽 여행지 10곳을 알려주세요. key: `places`. response in JSON format.\"\n",
    "\n",
    "# 체인 호출\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)  # 생성된 응답을 출력합니다."
   ],
   "id": "326d8536275facf5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**멀티모달(Multimodal) 지원**\n",
    "\n",
    "- Ollama는 [bakllava](https://ollama.ai/library/bakllava)와 [llava](https://ollama.ai/library/llava)와 같은 멀티모달 LLM을 지원\n",
    "- `tags`를 사용하여 [Llava](https://ollama.ai/library/llava/tags)와 같은 모델의 전체 버전 세트를 탐색 가능\n",
    "- `ollama pull llava:7b` 혹은 `ollama pull bakllava` 명령어를 통해 멀티모달 LLM을 다운로드\n",
    "- **참고**: 멀티모달을 지원하는 최신 버전을 사용하려면 Ollama를 업데이트"
   ],
   "id": "ad9c3f84b7abaf96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- 이미지를 인식하는 멀티모달을 구현하려면 먼저 이미지를 base64로 인코딩된 문자열로 변환하는 코드 필요\n",
    "- PIL 이미지를 Base64 인코딩된 문자열로 변환하고 이를 HTML에 포함하여 이미지를 표시하는 함수를 제공\n",
    "- `convert_to_base64` 함수:\n",
    "  - PIL 이미지를 입력으로 받는다.\n",
    "  - 이미지를 JPEG 형식으로 BytesIO 버퍼에 저장\n",
    "  - 버퍼의 값을 Base64로 인코딩하고 문자열로 반환\n",
    "- `plt_img_base64` 함수:\n",
    "  - Base64 인코딩된 문자열을 입력\n",
    "  - Base64 문자열을 소스로 사용하는 HTML `<img>` 태그를 생성\n",
    "  - HTML을 렌더링하여 이미지를 표시\n",
    "- 사용 예시:\n",
    "  - 지정된 파일 경로에서 PIL 이미지를 열어 `pil_image`에 저장\n",
    "  - `convert_to_base64` 함수를 사용하여 `pil_image`를 Base64 인코딩된 문자열로 변환\n",
    "  - `plt_img_base64` 함수를 사용하여 Base64 인코딩된 문자열을 이미지로 표시.\n"
   ],
   "id": "25818fe3144e55"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "def convert_to_base64(pil_image):\n",
    "    \"\"\"\n",
    "    PIL 이미지를 Base64로 인코딩된 문자열로 변환합니다.\n",
    "\n",
    "    :param pil_image: PIL 이미지\n",
    "    :return: 크기 조정된 Base64 문자열\n",
    "    \"\"\"\n",
    "\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"JPEG\")  # 필요한 경우 형식을 변경할 수 있습니다.\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return img_str\n",
    "\n",
    "\n",
    "def plt_img_base64(img_base64):\n",
    "    \"\"\"\n",
    "    Base64로 인코딩된 문자열을 이미지로 표시합니다.\n",
    "\n",
    "    :param img_base64:  Base64 문자열\n",
    "    \"\"\"\n",
    "    # Base64 문자열을 소스로 사용하여 HTML img 태그 생성\n",
    "    image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "    # HTML을 렌더링하여 이미지 표시\n",
    "    display(HTML(image_html))\n",
    "\n",
    "\n",
    "def prompt_func(data):  # 프롬프트 함수를 정의합니다.\n",
    "    text = data[\"text\"]  # 데이터에서 텍스트를 가져옵니다.\n",
    "    image = data[\"image\"]  # 데이터에서 이미지를 가져옵니다.\n",
    "\n",
    "    image_part = {  # 이미지 부분을 정의합니다.\n",
    "        \"type\": \"image_url\",  # 이미지 URL 타입을 지정합니다.\n",
    "        \"image_url\": f\"data:image/jpeg;base64,{image}\",  # 이미지 URL을 생성합니다.\n",
    "    }\n",
    "\n",
    "    content_parts = []  # 콘텐츠 부분을 저장할 리스트를 초기화합니다.\n",
    "\n",
    "    text_part = {\"type\": \"text\", \"text\": text}  # 텍스트 부분을 정의합니다.\n",
    "\n",
    "    content_parts.append(image_part)  # 이미지 부분을 콘텐츠 부분에 추가합니다.\n",
    "    content_parts.append(text_part)  # 텍스트 부분을 콘텐츠 부분에 추가합니다.\n",
    "\n",
    "    return [HumanMessage(content=content_parts)]  # HumanMessage 객체를 반환합니다.\n",
    "\n",
    "\n",
    "file_path = \"images/jeju-beach.jpg\"\n",
    "pil_image = Image.open(file_path)\n",
    "\n",
    "image_b64 = convert_to_base64(pil_image)\n",
    "\n",
    "plt_img_base64(image_b64)"
   ],
   "id": "a8fe4245f6b855a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- `ChatOllama` 언어 모델을 사용하여 이미지와 텍스트 기반 질의에 대한 답변을 생성하는 체인을 구현.\n",
    "- `prompt_func` 함수는 이미지와 텍스트 데이터를 입력으로 받아 `HumanMessage` 형식으로 변환.\n",
    "  - 이미지 데이터는 Base64 인코딩된 JPEG 형식으로 전달\n",
    "  - 텍스트 데이터는 일반 텍스트로 전달\n",
    "- `StrOutputParser`를 사용하여 언어 모델의 출력을 문자열로 파싱.\n",
    "- `prompt_func`, `llm`, `StrOutputParser`를 파이프라인으로 연결하여 `chain`을 생성\n",
    "- `chain.invoke` 메서드를 호출하여 이미지와 텍스트 질의를 전달하고 답변을 생성\n",
    "- 생성된 답변을 출력"
   ],
   "id": "d1d4327270fad04d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# ChatOllama 멀티모달 언어 모델을 불러옵니다.\n",
    "llm = ChatOllama(model=\"llava:7b\", temperature=0)\n",
    "\n",
    "# 프롬프트 함수, 언어 모델, 출력 파서를 연결하여 체인을 생성합니다.\n",
    "chain = prompt_func | llm | StrOutputParser()\n",
    "\n",
    "query_chain = chain.invoke(  # 체인을 호출하여 쿼리를 실행합니다.\n",
    "    # 텍스트와 이미지를 전달합니다.\n",
    "    {\"text\": \"Describe a picture in bullet points\", \"image\": image_b64}\n",
    ")\n",
    "\n",
    "print(query_chain)  # 쿼리 결과를 출력합니다.\n"
   ],
   "id": "eb3827896f350843"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
