{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# API KEY를 환경 변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보 로드\n",
    "load_dotenv()\n",
    "\n",
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH01-Basic\")"
   ],
   "id": "69605ad6db6b4b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"{country}의 수도는 어디인가요?\"  # template 정의\n",
    "\n",
    "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ],
   "id": "c8a50abfdc4e4f7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# prompt를 PromptTemplate 객체를 사용하여 생성\n",
    "prompt = PromptTemplate.from_template(\"{topic}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "chain = prompt | model"
   ],
   "id": "628ecb8eb56019e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "input 변수에 딕셔너리 형태로 {topic}과 그에 대한 입력값을 할당하고 invoke() 함수로 답변 출력",
   "id": "f4dad3050af16a4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# input 딕셔너리에 주제를 '인공지능 모델의 학습 원리'로 설정\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "\n",
    "# invoke 메서드를 사용하여 input을 전달해서 AI 모델이 생성한 메시지를 반환\n",
    "chain.invoke(input)"
   ],
   "id": "a09d6d56469b0023",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "invoke() 대신 스트리밍 출력",
   "id": "64fa5cfa07b25622"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "answer = chain.stream(input)\n",
    "stream_response(answer)"
   ],
   "id": "a1d5f0aefd78f861",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "프롬프트 템플릿 변수는 여러개 사용 가능",
   "id": "5ac08f04b09b787a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# prompt를 PromptTemplate 객체를 사용하여 생성\n",
    "prompt = PromptTemplate.from_template(\"{topic}에 대해 쉽게 {how} 설명해주세요\")\n",
    "model = ChatOpenAI()\n",
    "chain = prompt | model"
   ],
   "id": "87ba3e2a2df9e5a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "input 객체에 {how} 변수에 대한 입력값을 dictionary 형태로 지정하고 invoke() 실행",
   "id": "b2f494b001fb6711"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input = {\"topic\": \"인공지능 모델의 학습 원리\", \"how\": \"5살짜리도 이해할 수 있도록\"}\n",
    "chain.invoke(input)"
   ],
   "id": "6f0039a67bd33b2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# prompt를 PromptTemplate 객체를 사용하여 생성\n",
    "prompt = PromptTemplate.from_template(\"{topic}에 대해 쉽게 설명해주세요\")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}"
   ],
   "id": "6b42a6a0bc0e94b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LangChain에서 LLM의 응답을 문자열로 변환하는 파서인 `StringOutputParser`를 import 하고 해당 객체 생성",
   "id": "392210ed560d8b42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ],
   "id": "20aa8b045edc69d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "체인에 출력 파서 추가. 이제 LLM이 생성한 답변은 출력 파서가 해석(파싱)",
   "id": "d4e85d7da2807076"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인 구성\n",
    "chain = prompt | model | output_parser"
   ],
   "id": "371dc5f00b2cad04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "invoke() 함수로 답변 받으면 문자열로 된 답변 얻음",
   "id": "256c41123be71291"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "chain.invoke(input)"
   ],
   "id": "21ba7289e082d8a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T18:06:18.849571Z",
     "start_time": "2026-01-28T18:06:18.847663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 주어진 상황에 맞는 영어 회화를 작성해 주세요.\n",
    "양식은 [FORMAT]을 참고하여 작성해 주세요.\n",
    "\n",
    "#상황:\n",
    "{question}\n",
    "\n",
    "#FORMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석:\n",
    "\"\"\""
   ],
   "id": "ea1ed093e7eb01f7",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "프롬프트를 생성하고 모델과 출력 파서 초기화",
   "id": "ed258ea4fb2d7be1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T18:06:19.660042Z",
     "start_time": "2026-01-28T18:06:19.657296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 프롬프트 템플릿을 이용하여 프롬프트 생성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "model = ChatOpenAI(model_name=\"gpt-4-turbo\")\n",
    "\n",
    "# 문자열 출력 파서 초기화\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser"
   ],
   "id": "30d30950d00fa7ac",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "완성된 체인을 invoke() 함수로 출력. 프롬프트 템플릿을 잘 활용하면 질문과 답변에서 바뀌는 부분만 변수로 지정하고 정해진 형식에 따라 생성 가능",
   "id": "2f5fec47baca12c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T18:06:37.892035Z",
     "start_time": "2026-01-28T18:06:21.581601Z"
    }
   },
   "cell_type": "code",
   "source": "print(chain.invoke({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"}))",
   "id": "4b6e166e903aa6ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:\n",
      "  Customer: Excuse me, could I see the menu, please?\n",
      "  Waiter: Of course. Here's the menu. Would you like to start with something to drink?\n",
      "  Customer: Yes, I’d like a glass of sparkling water, please.\n",
      "  Waiter: Sparkling water, great choice. Are you ready to order, or would you like a few minutes?\n",
      "  Customer: I’ll need a few more minutes, thank you.\n",
      "\n",
      "- 한글 해석:\n",
      "  고객: 실례합니다, 메뉴판 좀 볼 수 있을까요?\n",
      "  웨이터: 물론입니다. 여기 메뉴판입니다. 음료로 무엇을 시작하시겠습니까?\n",
      "  고객: 네, 탄산수 한 잔 주세요.\n",
      "  웨이터: 탄산수, 좋은 선택이네요. 바로 주문하실래요, 아니면 조금 더 시간이 필요하신가요?\n",
      "  고객: 조금 더 시간이 필요할 것 같아요, 감사합니다.\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "이번에는 {question} 변수를 변경하고 스트리밍 출력",
   "id": "b8ad2a83d590a0e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T18:08:10.729766Z",
     "start_time": "2026-01-28T18:07:56.474584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "answer = chain.stream({\"question\": \"미국에서 피자 주문\"})\n",
    "stream_response(answer)"
   ],
   "id": "ed40b30f59445bfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:\n",
      "  A: Hello, I'd like to order a pizza for delivery, please.\n",
      "  B: Sure! What size would you like?\n",
      "  A: I'd like a large pizza.\n",
      "  B: What toppings would you like on that?\n",
      "  A: Could I have pepperoni, mushrooms, and extra cheese?\n",
      "  B: Absolutely, anything else?\n",
      "  A: Yes, could I also have a side of garlic bread?\n",
      "  B: Sure, one side of garlic bread. Anything to drink?\n",
      "  A: A bottle of Coke, please.\n",
      "  B: Alright, that's a large pizza with pepperoni, mushrooms, extra cheese, a side of garlic bread, and a bottle of Coke. Your total comes to $24.50. May I have your address?\n",
      "  A: It’s 123 Elm Street.\n",
      "  B: Great, your order will be there in about 30-40 minutes.\n",
      "  A: Thank you!\n",
      "\n",
      "- 한글 해석:\n",
      "  A: 안녕하세요, 배달로 피자 하나 주문하고 싶습니다.\n",
      "  B: 네! 피자 크기는 어떻게 하시겠어요?\n",
      "  A: 라지 사이즈로 부탁드립니다.\n",
      "  B: 어떤 토핑을 올려 드릴까요?\n",
      "  A: 페퍼로니, 버섯 그리고 치즈 추가해 주세요.\n",
      "  B: 알겠습니다, 추가로 더 필요한 것이 있나요?\n",
      "  A: 네, 갈릭 브레드도 하나 주문할게요.\n",
      "  B: 알겠습니다, 갈릭 브레드 하나요. 음료는 어떤 것으로 드릴까요?\n",
      "  A: 콜라 한 병 부탁드립니다.\n",
      "  B: 알겠습니다. 라지 사이즈 피자에 페퍼로니, 버섯, 치즈 추가, 갈릭 브레드, 콜라 한 병으로 총 24.50달러입니다. 주소를 알려주시겠어요?\n",
      "  A: 123 엘름 스트리트입니다.\n",
      "  B: 좋습니다, 주문하신 음식은 대략 30-40분 안에 도착할 거예요.\n",
      "  A: 감사합니다!"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4776929a03a47253"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
